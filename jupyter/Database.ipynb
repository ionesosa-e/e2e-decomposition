{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00cf2b2",
   "metadata": {},
   "source": [
    "# Database — Report\n",
    "\n",
    "This notebook visualizes the CSV outputs generated by the **Database** block.\n",
    "\n",
    "## What this notebook shows\n",
    "- **Tables by mapped entities**: Treemap and Bar (same metric in two formats).\n",
    "- **Field annotations**: Global top annotations (Bar).\n",
    "- **Relationship statistics**: Top entities by relationship count (Bar) and distribution (Histogram).\n",
    "- **Entity → Entity**: Optional Sankey if edges data is available.\n",
    "\n",
    "> If a CSV is missing or empty, the cell prints an info message and skips the chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports, paths, helpers\n",
    "# - CSVs are read from reports/csv-reports/<CATEGORY>/<file>.csv relative to this notebook folder.\n",
    "# - Minimal console output; only show information if a CSV is missing/empty.\n",
    "# - Bar charts use an explicit default color so it's easy to tweak later.\n",
    "# - Titles are standardized without block prefixes.\n",
    "\n",
    "import os, ast\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "CATEGORY = \"Database\"\n",
    "CSV_BASE = Path(\"../reports/csv-reports\").resolve()\n",
    "DB_DIR = CSV_BASE / CATEGORY\n",
    "\n",
    "# Explicit default color for all bar charts in this notebook\n",
    "DEFAULT_BAR_COLOR = [\"#1f77b4\"]\n",
    "\n",
    "# CSV IO helpers\n",
    "NA_LITS = [\"\", \" \", \"NA\", \"N/A\", \"n/a\", \"NaN\", \"NULL\", \"Null\", \"null\", \"None\", \"none\", \"-\", \"--\"]\n",
    "\n",
    "def read_csv_safe(p: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV if present; otherwise return an empty DataFrame.\n",
    "    Prints a minimal info message when missing or unreadable.\"\"\"\n",
    "    p = Path(p)\n",
    "    if not p.exists():\n",
    "        print(f\"[info] Missing CSV: {p}\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        df = pd.read_csv(p, na_values=NA_LITS, keep_default_na=True)\n",
    "        df.columns = [str(c).strip() for c in df.columns]\n",
    "        df = df.dropna(how=\"all\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] Failed to read {p}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def labelize_na(s, label=\"N/A\"):\n",
    "    s = s.copy()\n",
    "    s = s.mask(s.isna(), label).astype(str)\n",
    "    s = s.replace({\"nan\": label, \"NaN\": label})\n",
    "    return s\n",
    "\n",
    "def parse_listlike(x):\n",
    "    \"\"\"Return a list from cell x tolerant to JSON/Python lists or common separators.\"\"\"\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return [str(i).strip() for i in x if str(i).strip()]\n",
    "    s = str(x).strip()\n",
    "    if not s or s in {\"N/A\",\"NA\",\"null\",\"None\"}:\n",
    "        return []\n",
    "    if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "        try:\n",
    "            val = ast.literal_eval(s)\n",
    "            if isinstance(val, (list, tuple, set)):\n",
    "                return [str(i).strip() for i in val if str(i).strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    for sep in [\";\", \",\", \"|\"]:\n",
    "        if sep in s:\n",
    "            return [t.strip() for t in s.split(sep) if t.strip()]\n",
    "    return [s]\n",
    "\n",
    "def find_col(df, *cands, default=None, contains=None):\n",
    "    \"\"\"Find a column by exact candidates or by substring (contains).\"\"\"\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for c in cands:\n",
    "        if c and c.lower() in low:\n",
    "            return low[c.lower()]\n",
    "    if contains:\n",
    "        for k, orig in low.items():\n",
    "            if contains.lower() in k:\n",
    "                return orig\n",
    "    return default\n",
    "\n",
    "TOP_N = 40\n",
    "MAX_BARS = 25  # cap for long bar charts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1285b",
   "metadata": {},
   "source": [
    "## 1) Tables by Number of Mapped Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charts for Jpa_Entities\n",
    "# Where charts are generated (same metric, two visual encodings):\n",
    "#  - 1A) Tables by Number of Mapped Entities (Treemap)\n",
    "#  - 1B) Tables by Number of Mapped Entities (Bar, explicit color)\n",
    "\n",
    "path = DB_DIR / \"Jpa_Entities.csv\"\n",
    "df_ent = read_csv_safe(path)\n",
    "if not df_ent.empty:\n",
    "    c_entity = find_col(df_ent, \"Entity\", contains=\"entity\", default=\"Entity\")\n",
    "    c_table  = find_col(df_ent, \"TableName\", contains=\"table\", default=None)\n",
    "\n",
    "    if c_table is None:\n",
    "        print(\"[info] No TableName column found — skipping charts.\")\n",
    "    else:\n",
    "        tmp = pd.DataFrame({\n",
    "            \"entity\":  df_ent[c_entity].astype(str),\n",
    "            \"table\":   labelize_na(df_ent[c_table]),\n",
    "            \"value\":   1\n",
    "        })\n",
    "        agg = tmp.groupby(\"table\")[\"value\"].sum().reset_index(name=\"entities\")\n",
    "\n",
    "        # 1A) Treemap — same metric as bar, alternative representation\n",
    "        fig_treemap = px.treemap(agg, path=[\"table\"], values=\"entities\",\n",
    "                                 title=\"Tables by Number of Mapped Entities (Treemap)\")\n",
    "        fig_treemap.update_layout(width=1000, height=600)\n",
    "        fig_treemap.show()\n",
    "\n",
    "        # 1B) Bar — same metric as treemap, alternative representation\n",
    "        top_tabs = agg.sort_values(\"entities\", ascending=False).head(MAX_BARS)\n",
    "        fig_bar = px.bar(top_tabs, x=\"table\", y=\"entities\", text=\"entities\",\n",
    "                         title=\"Tables by Number of Mapped Entities (Bar)\",\n",
    "                         color_discrete_sequence=DEFAULT_BAR_COLOR)\n",
    "        fig_bar.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "        fig_bar.update_layout(xaxis_tickangle=-45, width=1100, height=550,\n",
    "                              xaxis_title=\"Table\", yaxis_title=\"Entities\")\n",
    "        fig_bar.show()\n",
    "else:\n",
    "    print(\"[info] Jpa_Entities.csv missing or empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a0a03",
   "metadata": {},
   "source": [
    "## 2) Field Annotations — Global Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0aa4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charts for Entity_Fields\n",
    "# Where chart is generated:\n",
    "#  - 2A) Top Field Annotations (Bar, explicit color)\n",
    "\n",
    "path = DB_DIR / \"Entity_Fields.csv\"\n",
    "df_fields = read_csv_safe(path)\n",
    "\n",
    "if not df_fields.empty:\n",
    "    c_entity = find_col(df_fields, \"Entity\", contains=\"entity\", default=\"Entity\")\n",
    "    c_ann    = find_col(df_fields, \"Annotations\", contains=\"annotation\", default=None)\n",
    "\n",
    "    if c_ann is None:\n",
    "        print(\"[info] No annotation-like column found — skipping chart.\")\n",
    "    else:\n",
    "        rows = []\n",
    "        for _, r in df_fields.iterrows():\n",
    "            ent = str(r.get(c_entity, \"\"))\n",
    "            for ann in parse_listlike(r.get(c_ann)):\n",
    "                rows.append({\"entity\": ent, \"annotation\": ann})\n",
    "        ann_df = pd.DataFrame(rows)\n",
    "\n",
    "        if ann_df.empty:\n",
    "            print(\"[info] No annotation entries parsed — skipping chart.\")\n",
    "        else:\n",
    "            top_ann = (ann_df.groupby(\"annotation\").size()\n",
    "                       .reset_index(name=\"count\")\n",
    "                       .sort_values(\"count\", ascending=False)\n",
    "                       .head(MAX_BARS))\n",
    "            fig = px.bar(top_ann, x=\"annotation\", y=\"count\", text=\"count\",\n",
    "                         title=\"Top Field Annotations\",\n",
    "                         color_discrete_sequence=DEFAULT_BAR_COLOR)\n",
    "            fig.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "            fig.update_layout(xaxis_tickangle=-40, width=1100, height=550,\n",
    "                              xaxis_title=\"Annotation\", yaxis_title=\"Count\")\n",
    "            fig.show()\n",
    "else:\n",
    "    print(\"[info] Entity_Fields.csv missing or empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027cb2d",
   "metadata": {},
   "source": [
    "## 3) Relationship Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charts for DB_Schema\n",
    "# Where charts are generated:\n",
    "#  - 3A) Top Entities by Relationships (Bar, explicit color)\n",
    "#  - 3B) Distribution of Relationships per Entity (Histogram)\n",
    "\n",
    "path = DB_DIR / \"DB_Schema.csv\"\n",
    "df_schema = read_csv_safe(path)\n",
    "\n",
    "if not df_schema.empty:\n",
    "    c_entity = find_col(df_schema, \"Entity\", contains=\"entity\", default=\"Entity\")\n",
    "    c_rel    = find_col(df_schema, \"Relationships\", contains=\"relationship\", default=None)\n",
    "\n",
    "    if c_rel is None:\n",
    "        print(\"[info] No 'Relationships' column found — skipping stats.\")\n",
    "    else:\n",
    "        rel_series = pd.to_numeric(df_schema[c_rel], errors=\"coerce\").fillna(0)\n",
    "        df_rel = pd.DataFrame({\n",
    "            \"Entity\": df_schema[c_entity].astype(str),\n",
    "            \"Relationships\": rel_series.astype(int)\n",
    "        })\n",
    "\n",
    "        # 3A) Top entities by relationships\n",
    "        top_rel = df_rel.sort_values(\"Relationships\", ascending=False).head(MAX_BARS)\n",
    "        fig = px.bar(top_rel, x=\"Entity\", y=\"Relationships\", text=\"Relationships\",\n",
    "                     title=\"Top Entities by Relationships\",\n",
    "                     color_discrete_sequence=DEFAULT_BAR_COLOR)\n",
    "        fig.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "        fig.update_layout(xaxis_tickangle=-45, width=1200, height=550,\n",
    "                          xaxis_title=\"Entity\", yaxis_title=\"Relationships\")\n",
    "        fig.show()\n",
    "\n",
    "        # 3B) Distribution (histogram)\n",
    "        fig2 = px.histogram(df_rel, x=\"Relationships\", nbins=20,\n",
    "                            title=\"Distribution of Relationships per Entity\")\n",
    "        fig2.update_layout(width=900, height=450, xaxis_title=\"Relationships\", yaxis_title=\"Count\")\n",
    "        fig2.show()\n",
    "else:\n",
    "    print(\"[info] DB_Schema.csv missing or empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2e67a",
   "metadata": {},
   "source": [
    "## 4) Entity → Entity by Relation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart for Entity_Relationship_Edges (optional)\n",
    "# Where chart is generated:\n",
    "#  - 4A) Entity → Entity by Relation (Sankey), only if edges CSV has valid rows\n",
    "\n",
    "path = DB_DIR / \"Entity_Relationship_Edges.csv\"\n",
    "df_edges = read_csv_safe(path)\n",
    "\n",
    "# Treat header-only as empty\n",
    "if not df_edges.empty and len(df_edges.dropna(how=\"all\")) > 0 and len(df_edges.columns) >= 3:\n",
    "    cols = {c.lower(): c for c in df_edges.columns}\n",
    "    c_from = cols.get(\"fromentity\") or \"fromEntity\"\n",
    "    c_to   = cols.get(\"toentity\") or \"toEntity\"\n",
    "    c_rel  = cols.get(\"relation\") or \"relation\"\n",
    "\n",
    "    e2e = df_edges.dropna(subset=[c_from, c_to])\n",
    "    if e2e.empty:\n",
    "        print(\"[info] Edges CSV has only empty rows — skipping Sankey.\")\n",
    "    else:\n",
    "        g = e2e.groupby([c_from, c_to, c_rel]).size().reset_index(name=\"count\")\n",
    "        # Cap nodes by degree to keep legible\n",
    "        deg = pd.concat([g.groupby(c_from)[\"count\"].sum(), g.groupby(c_to)[\"count\"].sum()], axis=1).fillna(0).sum(axis=1)\n",
    "        keep = set(deg.nlargest(80).index)  # keep manageable\n",
    "        g_c = g[g[c_from].isin(keep) & g[c_to].isin(keep)] if not deg.empty else g\n",
    "\n",
    "        ents = sorted(set(g_c[c_from].astype(str)).union(set(g_c[c_to].astype(str))))\n",
    "        if not ents:\n",
    "            print(\"[info] No edges after capping — skipping Sankey.\")\n",
    "        else:\n",
    "            idx = {name: i for i, name in enumerate(ents)}\n",
    "            src = [idx[s] for s in g_c[c_from].astype(str)]\n",
    "            tgt = [idx[t] for t in g_c[c_to].astype(str)]\n",
    "            val = g_c[\"count\"].tolist()\n",
    "            link_label = g_c[c_rel].astype(str).tolist()\n",
    "\n",
    "            fig = go.Figure(data=[go.Sankey(\n",
    "                arrangement=\"snap\",\n",
    "                node=dict(label=ents, pad=20, thickness=16),\n",
    "                link=dict(source=src, target=tgt, value=val, label=link_label))])\n",
    "            fig.update_layout(title_text=\"Entity → Entity by Relation (Optional)\",\n",
    "                              width=1200, height=700)\n",
    "            fig.show()\n",
    "else:\n",
    "    print(\"[info] Entity_Relationship_Edges.csv missing or empty — nothing to plot.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
